The concept of machine learning has continued to grow more popular for a multitude of tasks due to its ability to reduce human error and provide more efficient methods for solving real world problems. Prior to the advent of machine learning, programming was generally a practice in which a developer gave instructions to a computer explicitly and the machine executed the commands it received. In contrast, machine learning teaches a computer to “think” or develop a model on its own that can then be utilized to tackle new situations. For example, a classification-based system, such as the ones being used in this model, typically rely on large amounts of labelled data in the form of what is called a \textbf{training set}. \textbf{Labels} refer to the category of each instance in the dataset, so they would be “quality” (0) or “regular” (1) in this instance. The training set is typically fed to the model in \textbf{batches} (for computational speed and even label splits), where the model utilizes its \textbf{parameters} to generate predictions for the examples within the batch. These predictions are then compared to the actual labels of the set to calculate the \textbf{loss}, which measures the discrepancy between the predictions and intended results. Finally, an \textbf{optimizer} uses \textbf{back-propagation} (calculating the derivative of the final output with respect to each parameter) to update the parameters based on the loss. Machine learning typically also utilizes an evaluation and test dataset, which are used to monitor the progress of the model’s parameters. The model generates predictions on the evaluation set with a fixed frequency during training with back-propagation turned off. This allows the researcher to ensure that the model is not over-fitting on the training set, or becoming overly specific to the articles being trained on. Once evaluation performance begins to decrease, the model is then used to generate predictions on a test set to get a final list of results on completely new data. Assuming the test performance is adequate, the model can then be used to generate new predictions on unlabelled data, such as for the purpose of a recommendation application system that fetches new articles daily. The specific subset of machine learning that is utilized in this discussion is called \gls{NLP} which pertains to any type of model based on text analysis.